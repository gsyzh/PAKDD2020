{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "test = pd.read_csv('../data/test_b.csv')\n",
    "tag = pd.read_csv('../data/tag.csv')\n",
    "test['dt'] = test['dt'].apply(lambda x:''.join(str(x)[0:4] +'-'+ str(x)[4:6]  +'-'+ str(x)[6:]))\n",
    "test['dt'] = pd.to_datetime(test['dt'])\n",
    "tag['fault_time'] = pd.to_datetime(tag['fault_time'])\n",
    "#\n",
    "###tag表里面有的硬盘同一天发生几种故障\n",
    "tag['tag'] = tag['tag'].astype(str)\n",
    "tag = tag.groupby(['serial_number','fault_time','model'])['tag'].apply(lambda x :'|'.join(x)).reset_index()\n",
    "tag = tag.loc[tag.model==2]\n",
    "test = test.sort_values(['serial_number','dt'])\n",
    "test = test.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "###去掉全为空值和nunique为1的特征\n",
    "drop_list = []\n",
    "for i in tqdm([col for col in test.columns if col not in ['manufacturer', 'model']]):\n",
    "    if (test[i].nunique() == 1) & (test[i].isnull().sum() == 0):\n",
    "        drop_list.append(i)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['fea'] = test.isnull().sum().index\n",
    "df['isnull_sum'] = test.isnull().sum().values\n",
    "fea_list = list(set(df.loc[df.isnull_sum != test.shape[0]]['fea']) - set(drop_list))\n",
    "test = test[fea_list]\n",
    "#\n",
    "#提取jl.z\n",
    "train_2018_7 = read_from_local('../data/disk_sample_smart_log_201807.csv')\n",
    "# 7月只保留正样本\n",
    "train_2018_7 = train_2018_7.loc[train_2018_7.label == 1]\n",
    "joblib.dump(train_2018_7, '../user_data/train_2018_7.jl.z')\n",
    "del train_2018_7\n",
    "\n",
    "\n",
    "train_2018_6 = read_from_local('../data/disk_sample_smart_log_201806.csv')\n",
    "joblib.dump(train_2018_6, '../user_data/train_2018_6.jl.z')\n",
    "del train_2018_6\n",
    "\n",
    "train_2018_5 = read_from_local('../data/disk_sample_smart_log_201805.csv')\n",
    "joblib.dump(train_2018_5, '../user_data/train_2018_5.jl.z')\n",
    "del train_2018_5\n",
    "\n",
    "train_2018_4 = read_from_local('../data/disk_sample_smart_log_201804.csv')\n",
    "joblib.dump(train_2018_4, '../user_data/train_2018_4.jl.z')\n",
    "del train_2018_4\n",
    "\n",
    "train_2018_3 = read_from_local('../data/disk_sample_smart_log_201803.csv')\n",
    "joblib.dump(train_2018_3, '../user_data/train_2018_3.jl.z')\n",
    "del train_2018_3\n",
    "\n",
    "train_2018_2 = read_from_local('../data/disk_sample_smart_log_201802.csv')\n",
    "joblib.dump(train_2018_2, '../user_data/train_2018_2.jl.z')\n",
    "del train_2018_2\n",
    "\n",
    "train_2018_1 = read_from_local('../data/disk_sample_smart_log_201801.csv')\n",
    "joblib.dump(train_2018_1, '../user_data/train_2018_1.jl.z')\n",
    "del train_2018_1\n",
    "\n",
    "train_2017_7 = read_from_local('../data/disk_sample_smart_log_201707.csv')\n",
    "joblib.dump(train_2017_7, '../user_data/train_2017_7.jl.z')\n",
    "del train_2017_7\n",
    "\n",
    "train_2017_8 = read_from_local('../data/disk_sample_smart_log_201707.csv')\n",
    "joblib.dump(train_2017_8, '../user_data/train_2017_8.jl.z')\n",
    "del train_2017_8\n",
    "\n",
    "train_2017_9 = read_from_local('../data/disk_sample_smart_log_201709.csv')\n",
    "joblib.dump(train_2017_9, '../user_data/train_2017_9.jl.z')\n",
    "del train_2017_9\n",
    "\n",
    "train_2017_10 = read_from_local('../data/disk_sample_smart_log_201710.csv')\n",
    "joblib.dump(train_2017_10, '../user_data/train_2017_10.jl.z')\n",
    "del train_2017_10\n",
    "\n",
    "train_2017_11 = read_from_local('../data/disk_sample_smart_log_201711.csv')\n",
    "joblib.dump(train_2017_11, '../user_data/train_2017_11.jl.z')\n",
    "del train_2017_11\n",
    "\n",
    "train_2017_12 = read_from_local('../data/disk_sample_smart_log_201712.csv')\n",
    "joblib.dump(train_2017_12, '../user_data/train_2017_12.jl.z')\n",
    "del train_2017_12\n",
    "\n",
    "def get_serial(df):\n",
    "    df =df.loc[df.model == 2]\n",
    "    serialdf = df[['serial_number','dt','model']].sort_values('dt').drop_duplicates('serial_number')\n",
    "    serialdf = serialdf.sort_values('dt').drop_duplicates(subset=['serial_number','model']).reset_index(drop=True)\n",
    "    serialdf.columns = ['serial_number','dt_first','model']\n",
    "    serialdf.dt_first = pd.to_datetime(serialdf.dt_first)\n",
    "    df = serialdf\n",
    "    return df\n",
    "\n",
    "train_2018_7 = joblib.load('../user_data/train_2018_7.jl.z')\n",
    "serial_2018_7 = get_serial(train_2018_7)\n",
    "del train_2018_7\n",
    "\n",
    "\n",
    "train_2018_6 = joblib.load('../user_data/train_2018_6.jl.z')\n",
    "serial_2018_6 = get_serial(train_2018_6)\n",
    "del train_2018_6\n",
    "\n",
    "\n",
    "train_2018_5 = joblib.load('../user_data/train_2018_5.jl.z')\n",
    "serial_2018_5 = get_serial(train_2018_5)\n",
    "del train_2018_5\n",
    "\n",
    "\n",
    "train_2018_4 = joblib.load('../user_data/train_2018_4.jl.z')\n",
    "serial_2018_4 = get_serial(train_2018_4)\n",
    "del train_2018_4\n",
    "\n",
    "\n",
    "train_2018_3 = joblib.load('../user_data/train_2018_3.jl.z')\n",
    "serial_2018_3 = get_serial(train_2018_3)\n",
    "del train_2018_3\n",
    "\n",
    "\n",
    "train_2018_2 = joblib.load('../user_data/train_2018_2.jl.z')\n",
    "serial_2018_2 = get_serial(train_2018_2)\n",
    "del train_2018_2\n",
    "\n",
    "train_2018_1 = joblib.load('../user_data/train_2018_1.jl.z')\n",
    "serial_2018_1 = get_serial(train_2018_1)\n",
    "del train_2018_1\n",
    "\n",
    "\n",
    "train_2017_7 =  joblib.load('../user_data/train_2017_7.jl.z')\n",
    "serial_2017_7 = get_serial(train_2017_7)\n",
    "del train_2017_7\n",
    "\n",
    "\n",
    "train_2017_8 =  joblib.load('../user_data/train_2017_8.jl.z')\n",
    "serial_2017_8 = get_serial(train_2017_8)\n",
    "del train_2017_8\n",
    "\n",
    "\n",
    "train_2017_9 =  joblib.load('../user_data/train_2017_9.jl.z')\n",
    "serial_2017_9 = get_serial(train_2017_9)\n",
    "del train_2017_9\n",
    "\n",
    "\n",
    "train_2017_10 = joblib.load('../user_data/train_2017_10.jl.z')\n",
    "serial_2017_10 = get_serial(train_2017_10)\n",
    "del train_2017_10\n",
    "\n",
    "\n",
    "train_2017_11 = joblib.load('../user_data/train_2017_11.jl.z')\n",
    "serial_2017_11 = get_serial(train_2017_11)\n",
    "del train_2017_11\n",
    "\n",
    "\n",
    "train_2017_12 = joblib.load('../user_data/train_2017_12.jl.z')\n",
    "serial_2017_12 = get_serial(train_2017_12)\n",
    "del train_2017_12\n",
    "\n",
    "\n",
    "serial_2018_8 =  get_serial(test)\n",
    "\n",
    "\n",
    "serial = pd.concat((serial_2017_7,serial_2017_8,serial_2017_9,serial_2017_10,serial_2017_11,serial_2017_12),axis = 0)\n",
    "serial = pd.concat((serial,serial_2018_1,serial_2018_2,serial_2018_3,serial_2018_4,serial_2018_5,serial_2018_6,serial_2018_7,serial_2018_8),axis = 0)\n",
    "serial.columns = ['serial_number','dt','model']\n",
    "serial =  get_serial(serial)\n",
    "serial.to_csv(\"../user_data/serial.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
